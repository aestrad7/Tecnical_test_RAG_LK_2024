{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Llama2 and Solar Models\n",
    "This section outlines the preliminary tests that will be conducted with the Llama2 and Solar models to evaluate their performance in a local environment. The models have been configured to run completely locally, without the need for connection to external servers.\n",
    "![alt text](../sagemaker_documentation/images/Notebook1_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusions\n",
    "1. The tests conducted in this notebook have led to the conclusion that the local, llama2 (3GB) and solar (8GB) models are unable to process prompts and simple contexts of less than 20 tokens in an acceptable timeframe. As a result, the exercise will be developed using the OpenAI API as a proof of concept to accelerate the feasibility exploration.\n",
    "2. A locally stored vector storage may also require significant processing when scaling the solution, so it was decided to use the Chroma tools  [chroma](https://github.com/chroma-core/chroma) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayHnswSearch\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition:\n",
    "\n",
    "MODEL =\"gpt-3.5-turbo\"\n",
    "# MODEL = \"llama2\"\n",
    "# MODEL = \"solar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selector** The proposed development is intended to be executable and comparable with different models, two local models and the open AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Uganda is a landlocked country located in East Africa. It is bordered by South Sudan to the north, Kenya to the east, Tanzania to the south, Rwanda to the southwest, and the Democratic Republic of the Congo to the west. The capital city of Uganda is Kampala. The country is known for its diverse wildlife, including mountain gorillas, as well as its beautiful landscapes and friendly people. Uganda gained independence from British colonial rule in 1962.', response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 11, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-61680b69-e9c1-4a47-88cb-9c633eaa3de7-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model decision:\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(api_key=OPENAI_API_KEY, model= MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings()\n",
    "\n",
    "# test\n",
    "model.invoke(\"What is Uganda?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run times of the different models ####\n",
    ">- Gpt-3.5-turbo model takes 14 seconds\n",
    ">- Flame2 model takes 70 seconds\n",
    ">- The gpt-3.5-turbo model takes 440 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The embedding size is evaluated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"This is a test sentence.\"\n",
    "embedding_vector = embeddings.embed_documents([test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(*embedding_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangChain Testing and input and output Parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uganda is a country located in East Africa, bordered by Kenya to the east, South Sudan to the north, the Democratic Republic of the Congo to the west, Rwanda to the southwest, and Tanzania to the south. The capital city of Uganda is Kampala, and the official languages are English and Swahili. Uganda is known for its diverse wildlife, including the endangered mountain gorillas in Bwindi Impenetrable National Park, as well as its beautiful landscapes and friendly people.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse outputs\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser  \n",
    "chain.invoke(\"what is Uganda?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='AI Engineering\\nSenior ML Engineer Tech Assessment\\nIntroduction\\nThank you for accepting the technical challenge for Loka. The goal of this challenge is to evaluate\\nyour problem-solving skills, technical knowledge, and ability to put it into practice.\\nWe recommend that you first think through your solution and draft it before implementing as much\\nas possible. Note that Loka works closely with AWS, so we will highly value solutions that are cloud-\\ncompatible, particularly with AWS. We do not expect you to spend money or have a powerful machine at\\nyour disposal, so feel free to not deploy the most expensive/compute-intensive parts of your architecture\\nand just mock them (locally, on colab, or however makes sense to you).\\nWe provide you with a dataset of documents and a description of a general case that is common in the\\nfield and based on an internal project named Clementine. Note that for simplicity, the dataset provided\\nis AWS documentation (same as Clementine) that is widely available.\\nRemember that the goal of this challenge is for you to shine and show us what you know. You should\\nnot concern yourself too much if the output of your system isn’t the best you can do as long as you\\nclearly explain your architecture and design process. If you feel you have relevant skills that aren’t being\\nshowcased in this challenge, feel free to send us an email and explain the changes to the scenario you\\nwould propose and the skills you would like to showcase.\\nScenario\\nCompany X has a large amount of documentation that their developers need to navigate. They have\\nnoticed that their developers often spend significant amounts of time searching through documentation\\nor asking other developers simple questions that are in the documentation. The Company has reached\\nout to Loka to assist with building a tool to address this issue.\\nAfter some discussion, it is agreed that the first step of the collaboration should be a POC whose\\ngoal would be to prove that the system would significantly shorten the amount of time developers spend\\nlooking through documentation. The POC will cover only a subset of their data and will initially just be\\napplied to one of the teams.\\nUpon further investigation, they mention that their main goal would be to have a system that could\\nassist developers with parts of the documentation they aren’t familiar with, as in these cases they typically\\nreach out to coworkers with some pretty simple questions. This has several issues, among them experienced\\nmembers have their work interrupted often and responses are sometimes based on old information, as\\ndocumentation is often updated, causing problems down the line. They would also like for the system to\\nbe able to point the user to further reading, by pointing them towards the source for the response and\\ntowards other documents that may be relevant to what they are currently working on. However, this last\\nrequest is a nice-to-have and not a mandatory feature. They can accept this being implemented later.\\nThe documentation provided for the POC is public (it’s AWS documentation) and as such has no limi-\\ntations on usage. However, the final system will also handle internal documentation that contains sensitive\\ninformation that has proprietary (can’t be shared or accessed externally) and geographical restrictions\\n(can’t leave the US).\\nThey also provided some example questions they would like the system to be able to respond to for\\nthe POC:\\n1', metadata={'source': 'C:/Users/user/Documents/LOKA_Test/Senior_ML_Tech_Assessment_LOKA.pdf', 'page': 0}),\n",
       " Document(page_content='•What is SageMaker?\\n•What are all AWS regions where SageMaker is available?\\n•How to check if an endpoint is KMS encrypted?\\n•What are SageMaker Geospatial capabilities?\\nYour task is to design the overall solution for Company X. Determine what parts of that solution\\nshould be part of the POC and begin implementing the POC.\\nDeliverable\\nThe output of this exercise is expected to be a private GitHub repository. Please add the following\\nusers to the repository:\\n•@henriqueribeiro\\n•@caldasdeoliveira\\n•@tsfelg\\n•@ricardommarques\\n•@bojanilijoski\\n•@bonnec\\nSuggestions\\nSince we want to see you at your best, we’ll leave you with some tips and questions that we may ask\\nduring the interview. Feel free to use this section to help you prepare for the interview.\\n1. Does your solution solve the company’s pain points? What are they?\\n2. What is the name of the LLM Pattern you’ve used in this project? Since names are not yet\\nstandardized, feel free to elaborate on the pattern you used.\\n3. What tools did you use? Why did you select them?\\n4. What model would you use for this use case? Why?\\n(a) What did you use for your embeddings? How does that decision affect the performance of your\\nsystem?\\n5. How does your system handle out-of-vocabulary (OOV) terms?\\n6. Would you need to self-host? Explain your decision.\\n7. How did you chunk the documents provided? Does this decision have any effect on the performance\\nof the system?\\n8. What is missing for your solution to be production-ready?\\n9. Is your system able to handle changing information? What would happen if the documentation is\\nupdated?\\n2', metadata={'source': 'C:/Users/user/Documents/LOKA_Test/Senior_ML_Tech_Assessment_LOKA.pdf', 'page': 1}),\n",
       " Document(page_content='10. How can you evaluate your system?\\n(a) How do you evaluate your information retrieval system?\\n(b) What would need to be different between evaluation during development and for production?\\nAs always, if you have any questions regarding the scenario, the interview process, are unsure about\\nwhat to prioritize or implement, need extra information to make meaningful decisions, or any other point\\nthat you think the team can help clarify, feel free to send us an email with your questions, and we’ll try\\nto help you as much as possible.\\n3', metadata={'source': 'C:/Users/user/Documents/LOKA_Test/Senior_ML_Tech_Assessment_LOKA.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pdf in memory\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/user/Documents/LOKA_Test/Senior_ML_Tech_Assessment_LOKA.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
     ]
    }
   ],
   "source": [
    "for doc in pages:\n",
    "    print(dir(pages))  # This will display all attributes and methods available for the `doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based just on the context below. If you can't say 'i don't know.\n",
      "\n",
      "## dont give your opinion, or explanation just the replay based in the context.\n",
      "\n",
      "Context: here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template\n",
    "template = \"\"\"\n",
    "Answer the question based just on the context below. If you can't say 'i don't know.\n",
    "\n",
    "## dont give your opinion, or explanation just the replay based in the context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usable chain\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Andres.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name i was given is Andres\",\n",
    "        \"question\": \"what is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'space'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#TODO: Usar uno de verdad\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m vectores \u001b[38;5;241m=\u001b[39m \u001b[43mDocArrayHnswSearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/user/Documents/Code/rag_open_src_model_V0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1536\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores.py:550\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    549\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\docarray\\hnsw.py:107\u001b[0m, in \u001b[0;36mDocArrayHnswSearch.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, work_dir, n_dim, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_dim` parameter has not been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m store\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\docarray\\hnsw.py:74\u001b[0m, in \u001b[0;36mDocArrayHnswSearch.from_params\u001b[1;34m(cls, embedding, work_dir, n_dim, dist_metric, max_elements, index, ef_construction, ef, M, allow_replace_deleted, num_threads, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HnswDocumentIndex\n\u001b[0;32m     62\u001b[0m doc_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_doc_cls(\n\u001b[0;32m     63\u001b[0m     dim\u001b[38;5;241m=\u001b[39mn_dim,\n\u001b[0;32m     64\u001b[0m     space\u001b[38;5;241m=\u001b[39mdist_metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m doc_index \u001b[38;5;241m=\u001b[39m \u001b[43mHnswDocumentIndex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc_cls\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(doc_index, embedding)\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\docarray\\index\\backends\\hnswlib.py:116\u001b[0m, in \u001b[0;36mHnswDocumentIndex.__init__\u001b[1;34m(self, db_config, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_existing:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hnsw_indices[col_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading an existing index for column `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\docarray\\index\\backends\\hnswlib.py:407\u001b[0m, in \u001b[0;36mHnswDocumentIndex._load_index\u001b[1;34m(self, col_name, col)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, col_name: \u001b[38;5;28mstr\u001b[39m, col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ColumnInfo\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m hnswlib\u001b[38;5;241m.\u001b[39mIndex:\n\u001b[0;32m    406\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an existing HNSW index from disk.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_index_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     index\u001b[38;5;241m.\u001b[39mload_index(\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hnsw_locations[col_name], max_elements\u001b[38;5;241m=\u001b[39mcol\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_elements\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\docarray\\index\\backends\\hnswlib.py:416\u001b[0m, in \u001b[0;36mHnswDocumentIndex._create_index_class\u001b[1;34m(self, col)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_index_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ColumnInfo\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m hnswlib\u001b[38;5;241m.\u001b[39mIndex:\n\u001b[0;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an instance of hnswlib.index without initializing it.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 416\u001b[0m     construct_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_construct_params\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mn_dim:\n\u001b[0;32m    420\u001b[0m         construct_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39mn_dim\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\LOKA_Test\\.venv\\Lib\\site-packages\\docarray\\index\\backends\\hnswlib.py:417\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_index_class\u001b[39m(\u001b[38;5;28mself\u001b[39m, col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ColumnInfo\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m hnswlib\u001b[38;5;241m.\u001b[39mIndex:\n\u001b[0;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an instance of hnswlib.index without initializing it.\"\"\"\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     construct_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m--> 417\u001b[0m         (k, \u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_construct_params\n\u001b[0;32m    418\u001b[0m     )\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mn_dim:\n\u001b[0;32m    420\u001b[0m         construct_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39mn_dim\n",
      "\u001b[1;31mKeyError\u001b[0m: 'space'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vectores = DocArrayHnswSearch.from_documents(\n",
    "    pages,\n",
    "    embedding = embeddings,\n",
    "    work_dir = 'C:/Users/user/Documents/Code/rag_open_src_model_V0',\n",
    "    n_dim= 1536\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
